{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yush/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spotipy\n",
    "# from spotipy.oauth2 import SpotifyClientCredentials \n",
    "# spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id=CLIENT_ID, client_secret=CLIENT_SECRET))\n",
    "\n",
    "#uncomment above and replace CLIENT_ID and CLIENT_SECRET with the id and secret you get from creating your app with spotify (going through the \"Getting Started\" instructions in the Spotify Web API documentation)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discussions_df = pd.read_csv('data/Discussions.csv', header=0, encoding='utf-8')\n",
    "ratings_df = pd.read_csv('data/Ratings.csv', header=0, encoding='utf-8')\n",
    "\n",
    "# creating new columns and intializing each value to 0\n",
    "discussions_df['EnergyAvg'] = 0\n",
    "discussions_df['ValenceAvg'] = 0\n",
    "discussions_df['AcousticnessAvg'] = 0\n",
    "discussions_df['InstrumentalnessAvg'] = 0\n",
    "\n",
    "display(discussions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in range(len(discussions_df)):\n",
    "    results = spotify.album_tracks(discussions_df['SpotifyID'][ind]) # getting tracks from current album via SpotiPy\n",
    "\n",
    "    # filtering track ids into list\n",
    "    ids = []\n",
    "    for track in results['items']:\n",
    "        ids.append(track['id'])\n",
    "    numTracks = len(results['items'])\n",
    "\n",
    "    # getting features from each track in ids via SpotiPy\n",
    "    features = spotify.audio_features(ids)\n",
    "    for feature in features['audio_features']:\n",
    "        # calculating and storing average in df\n",
    "        discussions_df['EnergyAvg'][ind] += (feature['energy'] / numTracks)\n",
    "        discussions_df['ValenceAvg'][ind] += (feature['valence'] / numTracks)\n",
    "        discussions_df['AcousticnessAvg'][ind] += (feature['acousticness'] / numTracks)\n",
    "        discussions_df['InstrumentalnessAvg'][ind] += (feature['instrumentalness'] / numTracks)\n",
    "    time.sleep(3) # sleep with arbitrary time of 3 seconds for circumventing rate limit\n",
    "    \n",
    "display(discussions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discussions_df.to_csv(\"data/Discussions_Audio_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discussionsAF_df = pd.read_csv('data/Discussions_Audio_Features.csv', header=0, encoding='utf-8')\n",
    "\n",
    "ratings_df['WeightedEnergyRating'] = 0\n",
    "ratings_df['WeightedValenceRating'] = 0\n",
    "ratings_df['WeightedAcousticnessRating'] = 0\n",
    "ratings_df['WeightedInstrumentalnessRating'] = 0\n",
    "\n",
    "display(ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(discussionsAF_df, ratings_df, on='DiscussionID')\n",
    "merged_df = merged_df.drop(['AlbumName', 'ArtistName', 'Date', 'AvgRating', 'Stdev', 'Attendance', 'RotationGenre', 'OtherGenre','Subgenres','ReleaseYear','FavoriteTrack','Popularity','Tracks','SpotifyID','Image', 'Unnamed: 0', 'FavoriteTrack1', 'FavoriteTrack2', 'FavoriteTrack3'], axis='columns') #cleaning up df\n",
    "\n",
    "merged_df['WeightedEnergyRating'] = merged_df['Rating'] * merged_df['EnergyAvg']\n",
    "merged_df['WeightedValenceRating'] = merged_df['Rating'] * merged_df['ValenceAvg']\n",
    "merged_df['WeightedAcousticnessRating'] = merged_df['Rating'] * merged_df['AcousticnessAvg']\n",
    "merged_df['WeightedInstrumentalnessRating'] = merged_df['Rating'] * merged_df['InstrumentalnessAvg']\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Estimate with weighted ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard mu + b_i + b_u\n",
    "for AF in ['WeightedEnergyRating', 'WeightedValenceRating', 'WeightedAcousticnessRating', 'WeightedInstrumentalnessRating']:\n",
    "    X = merged_df.drop(columns=[AF])\n",
    "    y = merged_df[AF]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    X_train[AF] = y_train\n",
    "\n",
    "    mu = np.mean(X_train[AF])\n",
    "    y_pred = []\n",
    "    for idx, row in X_test.iterrows():\n",
    "        b_u = np.mean(X_train[X_train['MemberID'] == row['MemberID']][AF]) - mu\n",
    "        b_u = 0 if math.isnan(b_u) else b_u\n",
    "        b_i = np.mean(X_train[X_train['DiscussionID'] == row['DiscussionID']][AF]) - mu\n",
    "        b_i = 0 if math.isnan(b_i) else b_i\n",
    "        estimate = max(min(int(np.round(mu - b_u - b_i)), 10), 1)\n",
    "        y_pred.append(estimate)\n",
    "    y_pred = np.array(y_pred)\n",
    "    rmse = np.sqrt(np.mean((y_pred - y_test)**2))\n",
    "    print(AF + \" rmse: \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-User Collaborative Filtering with weighted Audio Feature Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    retValue = dot_product / (norm_vec1 * norm_vec2) if not math.isnan(dot_product / (norm_vec1 * norm_vec2)) else 0\n",
    "    return retValue\n",
    "\n",
    "def count_non_zeros(arr):\n",
    "    return sum(1 for num in arr if num != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "X = merged_df.drop(columns=['WeightedInstrumentalnessRating'])\n",
    "y = merged_df['WeightedInstrumentalnessRating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train['WeightedInstrumentalnessRating'] = y_train\n",
    "\n",
    "pivot_df = X_train.pivot(index='DiscussionID', columns='MemberID', values='WeightedInstrumentalnessRating')\n",
    "pivot_df = pivot_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 341\n",
    "album = 68\n",
    "user_sims = {}\n",
    "\n",
    "for member_id in pivot_df.columns:\n",
    "    if member_id != user:\n",
    "        print('User:', member_id)\n",
    "        print('Cosine Sim:', cosine_similarity(pivot_df[user], pivot_df[member_id]))\n",
    "        user_sims[member_id] = cosine_similarity(pivot_df[user], pivot_df[member_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/nhdtkkv14fj5w_ftm8sjrdt00000gn/T/ipykernel_3300/3092099898.py:5: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  retValue = dot_product / (norm_vec1 * norm_vec2) if not math.isnan(dot_product / (norm_vec1 * norm_vec2)) else 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.236919177526273\n"
     ]
    }
   ],
   "source": [
    "for idx, row in X_test.iterrows():\n",
    "    user = row['MemberID']\n",
    "    album = row['DiscussionID']\n",
    "    user_sims = {}\n",
    "    \n",
    "    if user not in pivot_df.columns:\n",
    "        y_pred.append(int(np.round(X_train['WeightedInstrumentalnessRating'].mean(),0)))\n",
    "        continue\n",
    "    if album not in pivot_df.index:\n",
    "        y_pred.append(int(np.round(X_train['WeightedInstrumentalnessRating'].mean(),0)))\n",
    "        continue\n",
    "\n",
    "    for member_id in pivot_df.columns:\n",
    "        if member_id != user:\n",
    "            user_sims[member_id] = cosine_similarity(pivot_df[user], pivot_df[member_id])\n",
    "\n",
    "    rated_users = []\n",
    "    for i in pivot_df.columns:\n",
    "        if pivot_df[i][album] != 0 and i != user:\n",
    "            rated_users.append(i)\n",
    "    rated_user_sims = []\n",
    "    for u in rated_users:\n",
    "        rated_user_sims.append(user_sims[u])\n",
    "\n",
    "    top5_rated_users = []\n",
    "    top5_sims = []\n",
    "    sorted_pairs = sorted(zip(rated_users, rated_user_sims), key=lambda x: x[1], reverse=True)\n",
    "    for top5_user, sim in sorted_pairs[:5]:\n",
    "        top5_rated_users.append(top5_user)\n",
    "        top5_sims.append(sim)\n",
    "    normalized_top5_sims = [x * sum(top5_sims) for x in normalized_top5_sims]\n",
    "\n",
    "    pred_r = 0\n",
    "    ind = 0\n",
    "    # # predict the rating with the weighted avg\n",
    "    for u in top5_rated_users:\n",
    "        pred_r += normalized_top5_sims[ind] * pivot_df[u][album]\n",
    "        ind += 1\n",
    "\n",
    "    y_pred.append(int(np.round(pred_r,0)))\n",
    "    \n",
    "y_pred = np.array(y_pred)\n",
    "rmse = np.sqrt(np.mean((y_pred - y_test)**2))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn\n",
    "Fill out the the database with audio features (watch out for 429 errors!) and run some of the filtering techniques we've covered on it.\n",
    "\n",
    "Content filtering is a great fit here\n",
    "\n",
    "also be cognisant of the fact that audio features are numerical values, and thus can be leveraged in weighted sums, numerical analysis, and any number of data science techniques.\n",
    "\n",
    "and like mentioned in the content filtering slides, feel free to go above and beyond with any external resoruces (like RateYourMusic, AlbumOfTheYear, etc.) you'd like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: integrate Spotify with your filtering code\n",
    "discussions_df['length'] = 0\n",
    "for ind in range(len(discussions_df)):\n",
    "    try:\n",
    "        results = spotify.album_tracks(discussions_df['SpotifyID'][ind]) # getting tracks from current album via SpotiPy\n",
    "\n",
    "        # filtering track ids into list\n",
    "        ids = []\n",
    "        for track in results['items']:\n",
    "            ids.append(track['id'])\n",
    "        numTracks = len(ids)\n",
    "        features = spotify.audio_features(ids)\n",
    "        for feature in features:\n",
    "            # calculating and storing average in df\n",
    "        \n",
    "            discussions_df['length'][ind] += round(feature['duration_ms'] / 60000, 2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "lengthy = discussions_df[['DiscussionID','AlbumName', 'length', 'AvgRating']]\n",
    "lengthy.set_index('AlbumName')\n",
    "lengthy = lengthy.drop_duplicates(subset=['AlbumName'])\n",
    "lengthy = lengthy[lengthy['length'] != 0]\n",
    "lengthy = lengthy[lengthy['AvgRating'] != 0]\n",
    "lengthyRating = lengthy.sort_values('AvgRating', ascending= False)\n",
    "lengthyLength = lengthy.sort_values('length', ascending= False)\n",
    "lengthyLength = lengthyLength.drop_duplicates(subset=['AlbumName'])\n",
    "display(lengthyRating.iloc[:10])\n",
    "\n",
    "\n",
    "\n",
    "X = ratings_df.drop(columns=['Rating'])\n",
    "y = ratings_df['Rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train['Rating'] = y_train\n",
    "\n",
    "merged_df = pd.merge(lengthy, X_train, on='DiscussionID')\n",
    "display(merged_df[[\"DiscussionID\", \"AlbumName\", \"length\", \"Rating\"]])\n",
    "y_pred = []\n",
    "for idx, row in X_test.iterrows():\n",
    "    # Get the decade of the current album\n",
    "    album_decade = discussions_df.loc[discussions_df['DiscussionID'] == row['DiscussionID'], 'length'].iloc[0]\n",
    "    \n",
    "    # Filter merged_df to only include discussions attended by the user and in the same decade\n",
    "    smaller_df = merged_df[(merged_df['MemberID'] == row['MemberID']) & (merged_df['length'] == album_decade)]\n",
    "    \n",
    "    # Calculate the average rating for discussions in the same decade\n",
    "    avg_rating = smaller_df['Rating'].mean() if not smaller_df.empty else X_train['Rating'].mean()\n",
    "    y_pred.append(int(np.round(avg_rating, 0)))\n",
    "\n",
    "# Calculate RMSE\n",
    "y_pred = np.array(y_pred)\n",
    "rmse = np.sqrt(np.mean((y_pred - y_test)**2))\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
